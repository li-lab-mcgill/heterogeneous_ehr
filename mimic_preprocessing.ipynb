{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/pnair6/venv/mcb36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_notes = pd.read_csv('../data/NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = pd.read_csv('../data/ADMISSIONS.csv')\n",
    "df_icu = pd.read_csv('../data/ICUSTAYS.csv')\n",
    "df_mechvent_d2 = pd.read_csv('../data/d2_mechvent_cohort08Oct19.csv')\n",
    "df_mechvent_d7 = pd.read_csv('../data/d7_mechvent_cohort27Sep19.csv')\n",
    "df_mechvent_d14 = pd.read_csv('../data/d14_mechvent_cohort27Sep19.csv')\n",
    "df_mechvent_entire = pd.read_csv('../data/entire_mechvent_cohort_starttimes15Oct19.csv')\n",
    "\n",
    "# add the INTIME Column from ICUSTAYS table\n",
    "df_mechvent_d2 = pd.merge(df_mechvent_d2, df_icu[['ICUSTAY_ID', 'INTIME']], on = ['ICUSTAY_ID'], how = 'inner')\n",
    "df_mechvent_entire = pd.merge(df_mechvent_entire, df_icu[['ICUSTAY_ID', 'INTIME']], on = ['ICUSTAY_ID'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    '''\n",
    "    Input\n",
    "        df: the initial cohort\n",
    "        \n",
    "    output\n",
    "        df_less_n_r: first icu stay cohort with notes within 48 hour starting from first vent time, with the following labels:\n",
    "            COHORT:\n",
    "                0 for not prolonged, 1 for more than 7 days, 2 for more than 14 days. So for prolonged for more than 7 days, should sum 1 & 2 cohort\n",
    "            LABEL:\n",
    "                0 for not prolonged, 1 for more than 7 days (including more than 14 days)\n",
    "            DEATH_90:\n",
    "                0 for not dead, 1 for dead within 90 days of 48 hours (action time) after first vent time \n",
    "            DAYS_UNTIL_DEATH: \n",
    "                continuous variable of days of death from the \n",
    "            \n",
    "            this table only returns notes that are in the respiratory, nurses and physician category\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    # only use the first ICU stays STARTING from the FIRST VENT TIME\n",
    "    df = df.sort_values(['HADM_ID','INTIME_x']).groupby('HADM_ID', as_index=False).first()\n",
    "    \n",
    "    # drop all the repetitive ventilation events, so now this df has each row correspond to unique one admission's first icu stay\n",
    "    df = df[['ICUSTAY_ID', 'HADM_ID', 'ADMITTIME','DISCHTIME','FIRST_VENT_STARTTIME', 'DOD']].drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    df.DOD = pd.to_datetime(df.DOD, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    df.ADMITTIME = pd.to_datetime(df.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    df.DISCHTIME = pd.to_datetime(df.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    df.FIRST_VENT_STARTTIME = pd.to_datetime(df.FIRST_VENT_STARTTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "    # cohort 0: not prolonged, 1: more than 7 days, 2: more than 14 days\n",
    "    df = df.assign(COHORT = [1 if i else 0 for i in (df.HADM_ID.isin(df_mechvent_d7.HADM_ID.unique()))])\n",
    "    df.loc[df.HADM_ID.isin(df_mechvent_d14.HADM_ID.unique()), 'COHORT'] = 2\n",
    "    count = df.groupby('COHORT').HADM_ID.nunique().values.tolist()\n",
    "    print('Not prolonged: {}, more than 7 days: {}, more than 14 days: {}'.format(count[0], count[1], count[2]))\n",
    "    \n",
    "    #to calculate the death label\n",
    "    df = df.assign(DAYS_UNTIL_DEATH = ((df['DOD']-df['FIRST_VENT_STARTTIME']).dt.total_seconds()/(60*60*24)))\n",
    "    df = df.assign(DEATH = [1 if i else 0 for i in (df.DAYS_UNTIL_DEATH < 7)])\n",
    "    df = df.assign(DEATH_90 = [1 if i else 0 for i in (df.DAYS_UNTIL_DEATH < 92)])\n",
    "    \n",
    "    df_curated = df.drop_duplicates().reset_index(drop = True)\n",
    "    print('n (number of admissions) is : {}'.format(len(df_curated.HADM_ID.unique())))\n",
    "    \n",
    "    # filter so that notes only in the admission cohort, in the CATEGORY we want\n",
    "    df_notes_cohort = df_notes[df_notes.HADM_ID.isin(df_curated.HADM_ID)]\n",
    "    print('removed subjects with no notes associated, n: {}'.format(len(df_notes_cohort.HADM_ID.unique())))\n",
    "\n",
    "    df_notes_cohort = pd.merge(df_notes_cohort[['HADM_ID', 'CHARTTIME', 'TEXT', 'CATEGORY']], df_curated, on = ['HADM_ID'], how = 'inner')\n",
    "    print('after merge, n: {}'.format(len(df_notes_cohort.HADM_ID.unique())))\n",
    "    \n",
    "    df_notes_cohort.CHARTTIME = pd.to_datetime(df_notes_cohort.CHARTTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    df_notes_cohort.ADMITTIME = pd.to_datetime(df_notes_cohort.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "        \n",
    "    TIME_to_VENT = ((df_notes_cohort['CHARTTIME']-df_notes_cohort['FIRST_VENT_STARTTIME']).dt.total_seconds()/(60*60))\n",
    "    df_less_n = df_notes_cohort[ (TIME_to_VENT<=48) & (TIME_to_VENT >=0)]\n",
    "    print('restricted to the first 48h, n: {}'.format(len(df_less_n.HADM_ID.unique())))\n",
    "    df_less_n = df_less_n.assign(Label = [1 if i else 0 for i in (df_less_n.COHORT != 0)])\n",
    "\n",
    "    df_less_n_r = df_less_n[df_less_n.CATEGORY.isin(['Nursing', 'Physician ', 'Respiratory '])]\n",
    "\n",
    "    print('remove subjects with no notes in the selected categories the entire admission, n: {}'.format(len(df_notes_cohort[df_notes_cohort.CATEGORY.isin(['Physician ', 'Nursing', 'Nursing/other'])].HADM_ID.unique())))\n",
    "    print('remove subjects with no notes in the selected categories under 48h, n: {}'.format(len(df_less_n_r.HADM_ID.unique())))\n",
    "    \n",
    "    print('# of notes restricted to the three categories: {}'.format(len(df_less_n_r)))\n",
    "    print('# of notes using all categories: {}'.format(len(df_less_n)))\n",
    "    \n",
    "    print('--- for prediction: below are label stats using three categories only ---')\n",
    "    \n",
    "    count = df_less_n_r.groupby('COHORT').HADM_ID.nunique().values.tolist()\n",
    "    print('Not prolonged: {}, prolonged: {}, out of which, more than 7 days: {}, more than 14 days: {}'.format(count[0], count[1]+count[2], count[1], count[2]))\n",
    "    count = df_less_n_r.groupby('DEATH').HADM_ID.nunique().values.tolist()\n",
    "    print('Not Death within 7 days: {}, Death within 7 days: {}'.format(count[0], count[1]))\n",
    "    \n",
    "    df_death = df_less_n_r[df_less_n_r.HADM_ID.isin(df_less_n_r.groupby('DEATH').HADM_ID.unique()[1])]\n",
    "    c = df_death[['HADM_ID','COHORT']].drop_duplicates().COHORT.value_counts().values\n",
    "    try:\n",
    "        print('Out of the {} death within 7 days, {} is from cohort not prolonged, {} is from cohort prolonged more than 7 days, and {} for 14 days'.format(count[1], c[0], c[1], c[2]))\n",
    "    except:\n",
    "        print('Out of the {} death within 7 days, {} is from cohort not prolonged, {} is from cohort prolonged more than 7 days, and 0 for 14 days'.format(count[1], c[0], c[1]))\n",
    "        \n",
    "    count = df_less_n_r.groupby('DEATH_90').HADM_ID.nunique().values.tolist()\n",
    "    print('Not Death within 90 days: {}, Death within 90 days: {}'.format(count[0], count[1]))\n",
    "      \n",
    "    return df_less_n_r.reset_index(drop = True)\n",
    "    #return df_less_n_r.reset_index(drop = True), df_less_n.reset_index(drop = True), df_physician.reset_index(drop = True), df_notes_cohort.reset_index(drop = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not prolonged: 5185, more than 7 days: 2424, more than 14 days: 1874\n",
      "n (number of admissions) is : 9483\n",
      "removed subjects with no notes associated, n: 9372\n",
      "after merge, n: 9372\n",
      "restricted to the first 48h, n: 9095\n",
      "remove subjects with no notes in the selected categories the entire admission, n: 7290\n",
      "remove subjects with no notes in the selected categories under 48h, n: 1545\n",
      "# of notes restricted to the three categories: 38246\n",
      "# of notes using all categories: 120108\n",
      "--- for prediction: below are label stats using three categories only ---\n",
      "Not prolonged: 908, prolonged: 637, out of which, more than 7 days: 376, more than 14 days: 261\n",
      "Not Death within 7 days: 1351, Death within 7 days: 194\n",
      "Out of the 194 death within 7 days, 192 is from cohort not prolonged, 2 is from cohort prolonged more than 7 days, and 0 for 14 days\n",
      "Not Death within 90 days: 1024, Death within 90 days: 521\n",
      "Not prolonged: 19634, more than 7 days: 2424, more than 14 days: 1874\n",
      "n (number of admissions) is : 23932\n",
      "removed subjects with no notes associated, n: 23748\n",
      "after merge, n: 23748\n",
      "restricted to the first 48h, n: 22681\n",
      "remove subjects with no notes in the selected categories the entire admission, n: 18040\n",
      "remove subjects with no notes in the selected categories under 48h, n: 4006\n",
      "# of notes restricted to the three categories: 78947\n",
      "# of notes using all categories: 234623\n",
      "--- for prediction: below are label stats using three categories only ---\n",
      "Not prolonged: 3369, prolonged: 637, out of which, more than 7 days: 376, more than 14 days: 261\n",
      "Not Death within 7 days: 3556, Death within 7 days: 450\n",
      "Out of the 450 death within 7 days, 448 is from cohort not prolonged, 2 is from cohort prolonged more than 7 days, and 0 for 14 days\n",
      "Not Death within 90 days: 3082, Death within 90 days: 924\n"
     ]
    }
   ],
   "source": [
    "df_less_n_d2 = process(df_mechvent_d2)\n",
    "df_less_n_entire = process(df_mechvent_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def preprocess1(x):\n",
    "    y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n",
    "    y=re.sub('[0-9]+\\.','',y) #remove 1.2. since the segmenter segments based on this\n",
    "    y=re.sub('dr\\.','doctor',y)\n",
    "    y=re.sub('m\\.d\\.','md',y)\n",
    "    y=re.sub('--|__|==','',y)\n",
    "    \n",
    "    # remove punctuation, digits, spaces\n",
    "    #y = y.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    y = y.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "    y = \" \".join(y.split())\n",
    "    return y\n",
    "\n",
    "def preprocessing_note(df_less_n): \n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].fillna(' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.replace('\\n',' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.replace('\\r',' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].apply(str.strip)\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.lower()\n",
    "\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].apply(lambda x: preprocess1(x))\n",
    "    \n",
    "    df_less_n['# of tokens'] = df_less_n['TEXT'].str.split().str.len()\n",
    "    df_less_n = df_less_n[df_less_n['# of tokens'] <=5]\n",
    "    return df_less_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use_d2 = preprocessing_note(df_less_n_d2) # day 2 cohort for training and cross-validation of classifier\n",
    "df_use_entire = preprocessing_note(df_less_n_entire) # entire cohort for learning topics using mixEHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one untouchable test set \n",
    "#df_HADM_ID = df_use.HADM_ID.drop_duplicates().reset_index(drop = True)\n",
    "#test_id = df_HADM_ID.sample(frac = 0.1, replace = False, random_state = 1)\n",
    "#test = df_use[df_use.HADM_ID.isin(test_id.values)]\n",
    "#test.reset_index(drop = True).to_csv('../data/data_files_18Nov/test.csv')\n",
    "\n",
    "#train_val_id = df_HADM_ID[~df_HADM_ID.index.isin(test_id.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
